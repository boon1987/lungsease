{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_372652/1482311168.py:6: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot  as plt\n",
    "import seaborn as sns\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0a0+44dac51\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('./LungDiseaseDataset/train.csv')\n",
    "train_set.rename(columns={'Pleural Effusion':'Effusion'}, inplace=True)\n",
    "display('original train_set',train_set.head())\n",
    "print()\n",
    "\n",
    "val_set = pd.read_csv('./LungDiseaseDataset/valid.csv')\n",
    "val_set.rename(columns={'Pleural Effusion':'Effusion'}, inplace=True)\n",
    "display('original val_set', val_set.head())\n",
    "print()\n",
    "\n",
    "bowen_dataset = pd.read_csv('./LungDiseaseDataset/CheXpert_dataset.csv')\n",
    "display('bowen_full_set', bowen_dataset.head())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display bowen dataset distribution\n",
    "display('Bowen Class Distribution', bowen_dataset.groupby('labels').count())\n",
    "print()\n",
    "\n",
    "# Display original dataset distribution\n",
    "bowen_classes = list(bowen_dataset.groupby('labels').groups.keys())\n",
    "display('Original ChesXpert Class Distribution', train_set.loc[:,bowen_classes].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set Distribution\n",
    "all_classes = ['No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax', 'Effusion', 'Pleural Other', 'Fracture', 'Support Devices']\n",
    "\n",
    "train_set_disease = train_set.loc[:,all_classes].fillna(-2).astype(np.int8)\n",
    "\n",
    "temp1 = (train_set_disease==1).sum(axis=1)\n",
    "sns.countplot(data=temp1.to_frame(), x=0)\n",
    "plt.title(\"Train Set\")\n",
    "plt.xlabel(\"Number for Simultaneous Observation Classes in the Same Patient Record\")\n",
    "plt.ylabel('Number of Patients')\n",
    "plt.tick_params(axis='x', labelrotation=0)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "m1=(train_set_disease==1).sum(axis=0)\n",
    "m0=(train_set_disease==0).sum(axis=0)\n",
    "mu=(train_set_disease==-1).sum(axis=0)\n",
    "mna=(train_set_disease==-2).sum(axis=0)\n",
    "train_set_disease_summary = pd.DataFrame([m1, m0, mu, mna]).transpose()\n",
    "train_set_disease_summary.columns=['Positive','Negative', 'Uncertain', 'No Mention']\n",
    "train_set_disease_summary.sort_values([\"Positive\",\"Negative\"]).plot(kind='bar', figsize=(20,10), stacked=True, rot=45)\n",
    "#train_set_disease_summary.iloc[:,:3].plot(kind='bar', figsize=(20,10))\n",
    "plt.tick_params('x', labelrotation=45)\n",
    "plt.title(\"Train Set\")\n",
    "plt.show()\n",
    "\n",
    "display(train_set_disease_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Val Set Distribution\n",
    "\n",
    "val_set_disease = val_set.loc[:,all_classes].fillna(-2).astype(np.int8)\n",
    "\n",
    "temp_acc = 0\n",
    "temp = (val_set.loc[:,all_classes].sum(axis=1)>1.5).sum()/val_set.shape[0]\n",
    "print(\"In validation set, {}% are multilabel patient.\".format(temp*100))\n",
    "temp_acc=temp\n",
    "\n",
    "temp = (val_set.loc[:,all_classes].sum(axis=1)<0.1).sum()/val_set.shape[0]\n",
    "print(\"In validation set, {}% are multilabel patient.\".format(temp*100))\n",
    "temp_acc = temp_acc + temp\n",
    "\n",
    "temp = (val_set.loc[:,all_classes].sum(axis=1)==1.0).sum()/val_set.shape[0]\n",
    "print(\"In validation set, {}% are multilabel patient.\".format(temp*100))\n",
    "temp_acc = temp_acc + temp\n",
    "\n",
    "assert int(temp_acc*100) == int(100)\n",
    "\n",
    "temp = val_set_disease.loc[:,all_classes].sum(axis=1)\n",
    "sns.countplot(temp.to_frame(), x=0)\n",
    "plt.xlabel(\"Number for Simultaneous Observation Classes in the Same Patient Record\")\n",
    "plt.ylabel('Number of Patients')\n",
    "plt.tick_params(axis='x', labelrotation=0)\n",
    "plt.title(\"Val Set\")\n",
    "plt.show()\n",
    "\n",
    "# display(val_set_disease.sum().sort_values())\n",
    "# ax = val_set_disease.sum().sort_values().plot(kind='bar',rot=45, figsize=(20,10), title=\"Multilabel Observation Class Distribution in Validation Set\")\n",
    "# ax.set_ylabel('Count')\n",
    "# plt.show()\n",
    "\n",
    "temp1=(val_set.loc[:,all_classes]==1).sum().sort_values()\n",
    "temp2=(val_set.loc[:,all_classes]==0).sum()\n",
    "temp=pd.DataFrame({\"1\":temp1, \"0\":temp2}).sort_values(\"1\")\n",
    "display(temp)\n",
    "temp.plot(kind='bar', rot=45, figsize=(20,10), stacked=True, title=\"Multilabel Observation Class Distribution in Validation Set\")\n",
    "\n",
    "# plt.figure(figsize=(20,10))\n",
    "# aa = temp.reset_index()\n",
    "# aa = aa.melt(id_vars='index')\n",
    "# axs = sns.barplot(data=aa, x='index', y='value', hue='variable')\n",
    "# axs.tick_params(axis='x', labelrotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect co-occurance\n",
    "train_set_disease_temp = train_set.loc[:,all_classes]\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(train_set_disease_temp.corr(numeric_only=False), annot=True, fmt=\".2f\")\n",
    "plt.title('Train Set Correlation Matrix Excluding NaN element (White color Heatmap entry has \"NaN\" value, because at least one involved column has non-varying value).')\n",
    "plt.show()\n",
    "\n",
    "val_set_disease_temp = val_set.loc[:,all_classes]\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(val_set_disease_temp.corr(numeric_only=False), annot=True, fmt=\".2f\")\n",
    "plt.title('Val Set Correlation Matrix Excluding NaN element (White color Heatmap entry has \"NaN\" value, because at least one involved column has non-varying value).')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "from PIL.ImageFile import Image\n",
    "\n",
    "from torch import as_tensor, int64, concat, cat\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Path', 'Sex', 'Age', 'Frontal/Lateral', 'AP/PA', 'No Finding',\n",
       "       'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity',\n",
       "       'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis',\n",
       "       'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture',\n",
       "       'Support Devices'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./LungDiseaseDataset/train.csv')\n",
    "df.head()\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_root_path, csv_path, disease_classes, transform=None, target_transform=None, data_root_directory=None):\n",
    "        self.img_labels = []\n",
    "        self.img_paths = []\n",
    "        \n",
    "        data = pd.read_csv(os.path.join(csv_path))\n",
    "        data_path = data.loc[:, 'Path'].to_numpy()\n",
    "        data_target = data.loc[:,disease_classes].to_numpy()\n",
    "\n",
    "        for path, target in zip(data_path, data_target):\n",
    "            self.img_labels.append(target)\n",
    "            self.img_paths.append(os.path.join(data_root_path, path))\n",
    "\n",
    "\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):     \n",
    "        image = self.img_paths[idx]\n",
    "        image = Image.open(self.img_paths[idx])\n",
    "        label = self.img_labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "            \n",
    "        #label = as_tensor([label], dtype=int64)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "csv_path = \"./LungDiseaseDataset/CheXpert-v1.0-small/train.csv\"\n",
    "disease_classes = ['No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture', 'Support Devices']\n",
    "\n",
    "\n",
    "dataset = CustomImageDataset(\"/home/boon1987/Desktop/temp/lung_disease/LungDiseaseDataset\", csv_path, disease_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader from Robus Deep AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as tfs\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import pdb\n",
    "\n",
    "class CheXpert(Dataset):\n",
    "    '''\n",
    "    Reference: \n",
    "        @inproceedings{yuan2021robust,\n",
    "            title={Large-scale Robust Deep AUC Maximization: A New Surrogate Loss and Empirical Studies on Medical Image Classification},\n",
    "            author={Yuan, Zhuoning and Yan, Yan and Sonka, Milan and Yang, Tianbao},\n",
    "            booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},\n",
    "            year={2021}\n",
    "            }\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 csv_path, \n",
    "                 image_root_path='',\n",
    "                 image_size=320,\n",
    "                 class_index=0, \n",
    "                 use_frontal=True,\n",
    "                 use_upsampling=True,\n",
    "                 flip_label=False,\n",
    "                 shuffle=True,\n",
    "                 seed=123,\n",
    "                 verbose=True,\n",
    "                 upsampling_cols=['Cardiomegaly', 'Consolidation'],\n",
    "                 train_cols=['Cardiomegaly', 'Edema', 'Consolidation', 'Atelectasis',  'Pleural Effusion'],\n",
    "                 mode='train'):\n",
    "        \n",
    "    \n",
    "        # load data from csv\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.df['Path'] = self.df['Path'].str.replace('CheXpert-v1.0-small/', '')\n",
    "        self.df['Path'] = self.df['Path'].str.replace('CheXpert-v1.0/', '')\n",
    "        if use_frontal:\n",
    "            self.df = self.df[self.df['Frontal/Lateral'] == 'Frontal']  \n",
    "            \n",
    "        # upsample selected cols\n",
    "        if use_upsampling:\n",
    "            assert isinstance(upsampling_cols, list), 'Input should be list!'\n",
    "            sampled_df_list = []\n",
    "            for col in upsampling_cols:\n",
    "                print ('Upsampling %s...'%col)\n",
    "                sampled_df_list.append(self.df[self.df[col] == 1])\n",
    "            self.df = pd.concat([self.df] + sampled_df_list, axis=0)\n",
    "\n",
    "\n",
    "        # impute missing values \n",
    "        for col in train_cols:\n",
    "            if col in ['Edema', 'Atelectasis']:\n",
    "                self.df[col].replace(-1, 1, inplace=True)        # Set uncertain observation disease to one (positive)\n",
    "                self.df[col].fillna(0, inplace=True)             # Set non-mention observation disease to zero (negative)\n",
    "            elif col in ['Cardiomegaly','Consolidation',  'Pleural Effusion']:\n",
    "                self.df[col].replace(-1, 0, inplace=True)        # Set uncertain observation disease to zero (negative)\n",
    "                self.df[col].fillna(0, inplace=True)             # Set non-mention observation disease to zero (negative)\n",
    "            else:\n",
    "                self.df[col].fillna(0, inplace=True)             # Set non-mention observation disease to zero (negative)\n",
    "        \n",
    "        self._num_images = len(self.df)\n",
    "        \n",
    "        # 0 --> -1\n",
    "        if flip_label and class_index != -1: # In multi-class mode we disable this option!\n",
    "            self.df.replace(0, -1, inplace=True)                 # In multiclass mode, randomly flip the negative to uncertain\n",
    "            \n",
    "        # shuffle data rows\n",
    "        if shuffle:\n",
    "            data_index = list(range(self._num_images))\n",
    "            np.random.seed(seed)\n",
    "            np.random.shuffle(data_index)\n",
    "            self.df = self.df.iloc[data_index]                    \n",
    "        \n",
    "        \n",
    "        assert class_index in [-1, 0, 1, 2, 3, 4], 'Out of selection!'\n",
    "        assert image_root_path != '', 'You need to pass the correct location for the dataset!'\n",
    "\n",
    "        if class_index == -1: # 5 classes\n",
    "            print ('Multi-label mode: True, Number of classes: [%d]'%len(train_cols))\n",
    "            self.select_cols = train_cols\n",
    "            self.value_counts_dict = {}\n",
    "            for class_key, select_col in enumerate(train_cols):\n",
    "                class_value_counts_dict = self.df[select_col].value_counts().to_dict()\n",
    "                self.value_counts_dict[class_key] = class_value_counts_dict\n",
    "        else:       # 1 class\n",
    "            self.select_cols = [train_cols[class_index]]  # this var determines the number of classes\n",
    "            self.value_counts_dict = self.df[self.select_cols[0]].value_counts().to_dict()\n",
    "        \n",
    "        self.mode = mode\n",
    "        self.class_index = class_index\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        self._images_list =  [image_root_path+path for path in self.df['Path'].tolist()]\n",
    "        if class_index != -1:\n",
    "            self._labels_list = self.df[train_cols].values[:, class_index].tolist()\n",
    "        else:\n",
    "            self._labels_list = self.df[train_cols].values.tolist()\n",
    "    \n",
    "        if verbose:\n",
    "            if class_index != -1:\n",
    "                print ('-'*30)\n",
    "                if flip_label:\n",
    "                    self.imratio = self.value_counts_dict[1]/(self.value_counts_dict[-1]+self.value_counts_dict[1])\n",
    "                    print('Found %s images in total, %s positive images, %s negative images'%(self._num_images, self.value_counts_dict[1], self.value_counts_dict[-1] ))\n",
    "                    print ('%s(C%s): imbalance ratio is %.4f'%(self.select_cols[0], class_index, self.imratio ))\n",
    "                else:\n",
    "                    self.imratio = self.value_counts_dict[1]/(self.value_counts_dict[0]+self.value_counts_dict[1])\n",
    "                    print('Found %s images in total, %s positive images, %s negative images'%(self._num_images, self.value_counts_dict[1], self.value_counts_dict[0] ))\n",
    "                    print ('%s(C%s): imbalance ratio is %.4f'%(self.select_cols[0], class_index, self.imratio ))\n",
    "                print ('-'*30)\n",
    "            else:\n",
    "                print ('-'*30)\n",
    "                imratio_list = []\n",
    "                for class_key, select_col in enumerate(train_cols):\n",
    "                    imratio = self.value_counts_dict[class_key][1]/(self.value_counts_dict[class_key][0]+self.value_counts_dict[class_key][1])\n",
    "                    imratio_list.append(imratio)\n",
    "                    print('Found %s images in total, %s positive images, %s negative images'%(self._num_images, self.value_counts_dict[class_key][1], self.value_counts_dict[class_key][0] ))\n",
    "                    print ('%s(C%s): imbalance ratio is %.4f'%(select_col, class_key, imratio ))\n",
    "                    print ()\n",
    "                self.imratio = np.mean(imratio_list)\n",
    "                self.imratio_list = imratio_list\n",
    "                print ('-'*30)\n",
    "            \n",
    "    @property        \n",
    "    def class_counts(self):\n",
    "        return self.value_counts_dict\n",
    "    \n",
    "    @property\n",
    "    def imbalance_ratio(self):\n",
    "        return self.imratio\n",
    "\n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return len(self.select_cols)\n",
    "       \n",
    "    @property  \n",
    "    def data_size(self):\n",
    "        return self._num_images \n",
    "    \n",
    "    def image_augmentation(self, image):\n",
    "        img_aug = tfs.Compose([tfs.RandomAffine(degrees=(-15, 15), translate=(0.05, 0.05), scale=(0.95, 1.05), fill=128)]) # pytorch 3.7: fillcolor --> fill\n",
    "        image = img_aug(image)\n",
    "        return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._num_images\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image = cv2.imread(self._images_list[idx], 0)\n",
    "        image = Image.fromarray(image)\n",
    "        if self.mode == 'train':\n",
    "            image = self.image_augmentation(image)\n",
    "        image = np.array(image)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "        \n",
    "        # resize and normalize; e.g., ToTensor()\n",
    "        image = cv2.resize(image, dsize=(self.image_size, self.image_size), interpolation=cv2.INTER_LINEAR)  \n",
    "        image = image/255.0\n",
    "        __mean__ = np.array([[[0.485, 0.456, 0.406]]])\n",
    "        __std__ =  np.array([[[0.229, 0.224, 0.225]  ]]) \n",
    "        image = (image-__mean__)/__std__\n",
    "        image = image.transpose((2, 0, 1)).astype(np.float32)\n",
    "        if self.class_index != -1: # multi-class mode\n",
    "            label = np.array(self._labels_list[idx]).reshape(-1).astype(np.float32)\n",
    "        else:\n",
    "            label = np.array(self._labels_list[idx]).reshape(-1).astype(np.float32)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_372652/2439040562.py:38: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df['Path'] = self.df['Path'].str.replace('CheXpert-v1.0-small/', '')\n",
      "/tmp/ipykernel_372652/2439040562.py:39: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df['Path'] = self.df['Path'].str.replace('CheXpert-v1.0/', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsampling Cardiomegaly...\n",
      "Upsampling Consolidation...\n",
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 227395 images in total, 48021 positive images, 179374 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.2112\n",
      "\n",
      "Found 227395 images in total, 77866 positive images, 149529 negative images\n",
      "Edema(C1): imbalance ratio is 0.3424\n",
      "\n",
      "Found 227395 images in total, 27217 positive images, 200178 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.1197\n",
      "\n",
      "Found 227395 images in total, 70593 positive images, 156802 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3104\n",
      "\n",
      "Found 227395 images in total, 94036 positive images, 133359 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.4135\n",
      "\n",
      "------------------------------\n",
      "Multi-label mode: True, Number of classes: [5]\n",
      "------------------------------\n",
      "Found 202 images in total, 66 positive images, 136 negative images\n",
      "Cardiomegaly(C0): imbalance ratio is 0.3267\n",
      "\n",
      "Found 202 images in total, 42 positive images, 160 negative images\n",
      "Edema(C1): imbalance ratio is 0.2079\n",
      "\n",
      "Found 202 images in total, 32 positive images, 170 negative images\n",
      "Consolidation(C2): imbalance ratio is 0.1584\n",
      "\n",
      "Found 202 images in total, 75 positive images, 127 negative images\n",
      "Atelectasis(C3): imbalance ratio is 0.3713\n",
      "\n",
      "Found 202 images in total, 64 positive images, 138 negative images\n",
      "Pleural Effusion(C4): imbalance ratio is 0.3168\n",
      "\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_372652/2439040562.py:38: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df['Path'] = self.df['Path'].str.replace('CheXpert-v1.0-small/', '')\n",
      "/tmp/ipykernel_372652/2439040562.py:39: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df['Path'] = self.df['Path'].str.replace('CheXpert-v1.0/', '')\n"
     ]
    }
   ],
   "source": [
    "root = \"/home/boon1987/Desktop/temp/lung_disease/LungDiseaseDataset/\"\n",
    "csv_path = \"/home/boon1987/Desktop/temp/lung_disease/LungDiseaseDataset/CheXpert-v1.0-small/\"\n",
    "root = '/home/boon1987/Desktop/temp/lung_disease/LungDiseaseDataset/CheXpert-v1.0-small/'\n",
    "train_cols=['Cardiomegaly', 'Edema', 'Consolidation', 'Atelectasis',  'Pleural Effusion']\n",
    "\n",
    "traindSet = CheXpert(csv_path=root+'train.csv', image_root_path=root, use_upsampling=True, use_frontal=True, image_size=320, mode='train', class_index=-1)\n",
    "testSet =  CheXpert(csv_path=root+'valid.csv',  image_root_path=root, use_upsampling=False, use_frontal=True, image_size=320, mode='valid', class_index=-1)\n",
    "trainloader =  torch.utils.data.DataLoader(traindSet, batch_size=32, num_workers=2, drop_last=True, shuffle=True)\n",
    "testloader =  torch.utils.data.DataLoader(testSet, batch_size=32, num_workers=2, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.63385719, 2.36766206],\n",
       "       [0.7603709 , 1.46016875],\n",
       "       [0.567982  , 4.17744424],\n",
       "       [0.72510236, 1.61060587],\n",
       "       [0.85256713, 1.20908482]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute balanced class weight for multilabel classification\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "temp_targets = np.array(traindSet.df.loc[:, traindSet.select_cols]).astype(dtype=np.int64)\n",
    "\n",
    "class_weights=[]\n",
    "for i in np.arange(temp_targets.shape[1]):\n",
    "    temp_y = temp_targets[:,i]\n",
    "    class_weights.append(list(compute_class_weight('balanced', np.array([0,1]), y=temp_y)))\n",
    "class_weights = np.array(class_weights)\n",
    "display(class_weights)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "from torchvision.models import resnet50, ResNet50_Weights, densenet121, DenseNet121_Weights\n",
    "\n",
    "img = read_image(\"./LungDiseaseDataset/CheXpert-v1.0-small/train/patient00001/study1/view1_frontal.jpg\")\n",
    "img = np.repeat(img, repeats=3, axis=0)\n",
    "\n",
    "# Step 1: Initialize model with the best available weights\n",
    "weights = DenseNet121_Weights.DEFAULT\n",
    "model = densenet121(weights=weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isopod: 28.5%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Step 2: Initialize the inference transforms\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "# Step 3: Apply inference preprocessing transforms\n",
    "batch = preprocess(img).unsqueeze(0)\n",
    "\n",
    "# Step 4: Use the model and print the predicted category\n",
    "prediction = model(batch).squeeze(0).softmax(0)\n",
    "class_id = prediction.argmax().item()\n",
    "score = prediction[class_id].item()\n",
    "category_name = weights.meta[\"categories\"][class_id]\n",
    "print(f\"{category_name}: {100 * score:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libauc.models import densenet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    (elu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (ELU): ReLU(inplace=True)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (ELU): ReLU(inplace=True)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (ELU): ReLU(inplace=True)\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (elu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = densenet121(pretrained=False)\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Non-empty 4D data tensor expected but got a tensor with sizes [1, 0, 320, 389]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m preprocess \u001b[39m=\u001b[39m weights\u001b[39m.\u001b[39mtransforms()\n\u001b[1;32m      7\u001b[0m \u001b[39m# Step 3: Apply inference preprocessing transforms\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m batch \u001b[39m=\u001b[39m preprocess(img)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m     10\u001b[0m batch \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     11\u001b[0m model(batch)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1480\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1475\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1476\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1477\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1478\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1479\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1480\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1481\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1482\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/_presets.py:56\u001b[0m, in \u001b[0;36mImageClassification.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, img: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 56\u001b[0m     img \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mresize(img, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresize_size, interpolation\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterpolation)\n\u001b[1;32m     57\u001b[0m     img \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcenter_crop(img, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrop_size)\n\u001b[1;32m     58\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(img, Tensor):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:480\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    477\u001b[0m     pil_interpolation \u001b[39m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m F_pil\u001b[39m.\u001b[39mresize(img, size\u001b[39m=\u001b[39moutput_size, interpolation\u001b[39m=\u001b[39mpil_interpolation)\n\u001b[0;32m--> 480\u001b[0m \u001b[39mreturn\u001b[39;00m F_t\u001b[39m.\u001b[39;49mresize(img, size\u001b[39m=\u001b[39;49moutput_size, interpolation\u001b[39m=\u001b[39;49minterpolation\u001b[39m.\u001b[39;49mvalue, antialias\u001b[39m=\u001b[39;49mantialias)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional_tensor.py:461\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, antialias)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39m# Define align_corners to avoid warnings\u001b[39;00m\n\u001b[1;32m    459\u001b[0m align_corners \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m interpolation \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mbilinear\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbicubic\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m img \u001b[39m=\u001b[39m interpolate(img, size\u001b[39m=\u001b[39;49msize, mode\u001b[39m=\u001b[39;49minterpolation, align_corners\u001b[39m=\u001b[39;49malign_corners, antialias\u001b[39m=\u001b[39;49mantialias)\n\u001b[1;32m    463\u001b[0m \u001b[39mif\u001b[39;00m interpolation \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbicubic\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m out_dtype \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39muint8:\n\u001b[1;32m    464\u001b[0m     img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mclamp(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, \u001b[39mmax\u001b[39m\u001b[39m=\u001b[39m\u001b[39m255\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:3952\u001b[0m, in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   3950\u001b[0m     \u001b[39mif\u001b[39;00m antialias:\n\u001b[1;32m   3951\u001b[0m         \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39m_upsample_bilinear2d_aa(\u001b[39minput\u001b[39m, output_size, align_corners, scale_factors)\n\u001b[0;32m-> 3952\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mupsample_bilinear2d(\u001b[39minput\u001b[39;49m, output_size, align_corners, scale_factors)\n\u001b[1;32m   3953\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m5\u001b[39m \u001b[39mand\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtrilinear\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   3954\u001b[0m     \u001b[39massert\u001b[39;00m align_corners \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Non-empty 4D data tensor expected but got a tensor with sizes [1, 0, 320, 389]"
     ]
    }
   ],
   "source": [
    "img = read_image(\"./LungDiseaseDataset/CheXpert-v1.0-small/train/patient00001/study1/view1_frontal.jpg\")\n",
    "img = np.repeat(img, axis=0, repeats=0)\n",
    "\n",
    "# Step 2: Initialize the inference transforms\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "# Step 3: Apply inference preprocessing transforms\n",
    "batch = preprocess(img).unsqueeze(0)\n",
    "\n",
    "batch = batch.cuda()\n",
    "model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramaters\n",
    "SEED = 123\n",
    "BATCH_SIZE = 32\n",
    " \n",
    "lr = 0.1 # using smaller learning rate is better\n",
    "gamma = 500\n",
    "imratio = traindSet.imratio_list \n",
    "weight_decay = 1e-5\n",
    "margin = 1.0\n",
    "\n",
    "# model\n",
    "model = densenet121(pretrained=True, last_activation=None, activations='relu', num_classes=5)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in trainloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('/home/boon1987/Desktop/temp/lung_disease/LungDiseaseDataset/CheXpert-v1.0-small/train/patient17953/study5/view1_frontal.jpg', 0)\n",
    "image = Image.fromarray(image)\n",
    "image = np.array(image)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([[1, 2,3], [4,5,6],[7,8,9],[10,11,12]]).float()\n",
    "display(t.shape)\n",
    "display(t)\n",
    "index = torch.tensor([[0,0],[2,3],[1,2]])\n",
    "display(index, index.shape)\n",
    "display( torch.gather(t, 0, index) )\n",
    "#torch.gather(t, 1, torch.tensor([[0, 0], [1, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([ [[1, 2,3], [4,5,6],[7,8,9],[10,11,12]], [[13, 14,15], [16,17,18],[7,8,9],[10,11,12]] ]).float()\n",
    "t.shape\n",
    "t.data.view((-1,2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# test without view\n",
    "X = torch.tensor([[[0.25]],[[ 0.75]]],requires_grad=True,)\n",
    "Y = torch.tensor([[[0.25]],[[ 0.75]]],requires_grad=True,)\n",
    "y=(X*Y)**2\n",
    "y.sum().backward()\n",
    "print(f\"X.grad: {X.grad, Y.grad}\")\n",
    "y=(X*Y)**2\n",
    "y.sum().backward()\n",
    "print(f\"X.grad: {X.grad, Y.grad}\")\n",
    "# y=(X*Y)**2\n",
    "# y.sum().backward()\n",
    "# print(f\"X.grad: {X.grad, Y.grad}\")\n",
    "\n",
    "# # print()\n",
    "\n",
    "# test with view\n",
    "X.grad.zero_()\n",
    "Y.grad.zero_()\n",
    "print(f\"X.grad: {X.grad, Y.grad}\")\n",
    "\n",
    "\n",
    "X_view = X.view((2,1,1))\n",
    "y=(X_view*Y)**2\n",
    "y.sum().backward()\n",
    "print(f\"X.grad: {X.grad, Y.grad, X_view.grad}\")\n",
    "y=(X_view*Y)**2\n",
    "y.sum().backward()\n",
    "print(f\"X.grad: {X.grad, Y.grad, X_view.grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "input = torch.randn(3, requires_grad=True)\n",
    "target = torch.empty(3).random_(2)\n",
    "output = loss(input, target)\n",
    "output.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b-a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create custom multilabel focal loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class Custom_MultiLabel_FocalLoss(torch.nn.Module): \n",
    "    \"\"\"\n",
    "    Focal Loss: Modified based on the libauc focal loss\n",
    "    Reference: https://amaarora.github.io/2020/06/29/FocalLoss.html\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=None, gamma=2, num_classes=5):\n",
    "        super(Custom_MultiLabel_FocalLoss, self).__init__()\n",
    "        if alpha is None:\n",
    "            self.alpla = (torch.tensor([1.0]*5)).repeat(2, 1)\n",
    "            self.alpha = self.alpla.cuda()\n",
    "        else:\n",
    "            self.alpha = torch.tensor(alpha).cuda()\n",
    "        self.gamma = torch.tensor(gamma).cuda()\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "\n",
    "            \n",
    "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "\n",
    "\n",
    "        # Modified for multilabel classification\n",
    "        targets = targets.type(torch.long)\n",
    "        at = self.alpha.gather(dim=0, index=targets)\n",
    "        display(self.alpha)\n",
    "        display(targets)\n",
    "        display('at',at)\n",
    "        display('pt',pt)\n",
    "        display('BCE_loss', BCE_loss)\n",
    "        F_loss = at.view(-1)*(1-pt.view(-1))**self.gamma * BCE_loss.view(-1)\n",
    "\n",
    "        return F_loss.mean()\n",
    "\n",
    "\n",
    "def calculate_multilabel_class_weight(targets):\n",
    "    # Compute balanced class weight for multilabel classification\n",
    "\n",
    "    class_weights=[]\n",
    "    for i in np.arange(targets.shape[1]):\n",
    "        temp_y = targets[:,i]\n",
    "        class_weights.append(list(compute_class_weight('balanced', np.array([0,1]), y=temp_y)))\n",
    "    class_weights = torch.as_tensor(np.array(class_weights).transpose())\n",
    "    return class_weights\n",
    "\n",
    "temp_targets = np.array(traindSet.df.loc[:, traindSet.select_cols]).astype(dtype=np.int64).copy()\n",
    "class_weights = torch.as_tensor(calculate_multilabel_class_weight(temp_targets))\n",
    "display(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ln1 = Custom_MultiLabel_FocalLoss()\n",
    "loss_ln2 = Custom_MultiLabel_FocalLoss(alpha=class_weights)\n",
    "display(loss_ln1.alpha, loss_ln2.alpha)\n",
    "\n",
    "for x, y in trainloader:\n",
    "    break\n",
    "ypred=torch.randint_like(y, high=2, dtype=torch.float64)\n",
    "display(x.shape, y.shape, ypred.shape)\n",
    "\n",
    "loss_ln1(ypred.cuda(), y.cuda())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(torch.backends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 25, 25])\n",
      "torch.Size([1, 3, 25, 25])\n",
      "tensor([0.4424, 0.2022, 0.5121, 0.3441, 0.4273, 0.0000, 0.0000, 0.4418, 0.0000,\n",
      "        0.0000], grad_fn=<SliceBackward0>)\n",
      "tensor([0.4424, 0.2022, 0.5121, 0.3441, 0.4273, 0.0000, 0.0000, 0.4418, 0.0000,\n",
      "        0.0000], grad_fn=<SliceBackward0>)\n",
      "tensor([0.4424, 0.2022, 0.5121, 0.3441, 0.4273, 0.0000, 0.0000, 0.4418, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.1970, 0.2277, 0.4336],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([0.4424, 0.2022, 0.5121, 0.3441, 0.4273, 0.0000, 0.0000, 0.4418, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.1970, 0.2277, 0.4336],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/jit/_script.py:1243: UserWarning: `optimize` is deprecated and has no effect. Use `with torch.jit.optimized_execution() instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Define model\n",
    "class TheModelClass(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TheModelClass, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 3, 3, padding=\"same\")\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #x = self.pool(F.relu(self.conv1(x)))\n",
    "        # x = self.pool(F.relu(self.conv2(x)))\n",
    "        # x = x.view(-1, 1)\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        # x = F.relu(self.fc2(x))\n",
    "        # x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = TheModelClass()\n",
    "output = model(torch.randn((1, 3, 20, 20)))\n",
    "output.size()\n",
    "\n",
    "model_traced1 = torch.jit.script(model, torch.randn(1,3,26,27))\n",
    "model_traced2 = torch.jit.script(model, torch.randn(1,3,28,29))\n",
    "x = torch.randn(1,3,25,25)\n",
    "print(model_traced1(x).size())\n",
    "print(model_traced2(x).size())\n",
    "print(model_traced1(x)[0,0,0,:10])\n",
    "print(model_traced2(x)[0,0,0,:10])\n",
    "print(model_traced1(x)[0,0,0,:-10])\n",
    "print(model_traced2(x)[0,0,0,:-10])\n",
    "\n",
    "# # Initialize optimizer\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# # Print model's state_dict\n",
    "# print(\"Model's state_dict:\")\n",
    "# for param_tensor in model.state_dict():\n",
    "#     print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# # Print optimizer's state_dict\n",
    "# print(\"Optimizer's state_dict:\")\n",
    "# for var_name in optimizer.state_dict():\n",
    "#     print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_traced1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39msave(model_traced1, \u001b[39m'\u001b[39m\u001b[39m./model_trace\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_traced1' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.jit.save(model_traced1, './model_trace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  conv1 = self.conv1\n",
      "  x0 = __torch__.torch.nn.functional.relu((conv1).forward(x, ), False, )\n",
      "  return x0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_traced_load = torch.jit.load('./model_trace')\n",
    "print(model_traced_load.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch, time\n",
    "\n",
    "class MyModule(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.linear = torch.nn.Linear(4, 4, bias=False)\n",
    "    \n",
    "    def forward(self, xs):\n",
    "        h = torch.zeros(3, 4)\n",
    "        for i in range(xs.size(0)):\n",
    "            h = torch.tanh(h + self.linear(xs[i]))\n",
    "        return h\n",
    "\n",
    "mymod = MyModule()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[8.6650, 7.0595, 8.5649, 4.8167],\n",
      "        [0.8052, 0.6646, 0.4260, 0.3602],\n",
      "        [9.2512, 7.7348, 9.0918, 5.0951],\n",
      "        [1.6403, 1.0277, 1.0677, 0.8306]])]\n",
      "[None]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = torch.rand(10, 3, 4)\n",
    "y = mymod(x)\n",
    "y.sum().backward()\n",
    "\n",
    "print([i.grad for i in mymod.parameters()])\n",
    "mymod.zero_grad(set_to_none=True)\n",
    "print([i.grad for i in mymod.parameters()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a=time.time()\n",
    "for i in range(10000):\n",
    "    y = mymod(x)\n",
    "b=time.time()\n",
    "print(b-a)\n",
    "\n",
    "\n",
    "y.sum().backward()\n",
    "mymod.zero_grad\n",
    "mymod.zero_grad(set_to_none=True)\n",
    "mymod = mymod.train()\n",
    "traced_mymod = torch.jit.trace(mymod,x)\n",
    "a=time.time()\n",
    "for i in range(10000):\n",
    "    y = traced_mymod(x)\n",
    "b=time.time()\n",
    "print(b-a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymod.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-3.0542e-01,  2.7690e-01, -1.3966e-01, -3.3996e-01],\n",
      "        [ 2.3003e-01,  4.1637e-01, -9.5947e-02, -7.6008e-02],\n",
      "        [ 9.9899e-02, -3.4648e-04, -4.9217e-01,  4.8397e-01],\n",
      "        [ 3.5403e-01,  3.6949e-02,  2.3214e-01, -1.8929e-02]],\n",
      "       requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print([i for i in mymod.linear.parameters()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
